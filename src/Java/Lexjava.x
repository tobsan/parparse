-- -*- haskell -*-
-- This Alex file was machine-generated by the BNF converter
{
{-# OPTIONS -fno-warn-incomplete-patterns #-}
module Lexjava where

import Data.FingerTree (FingerTree)
import qualified Data.FingerTree as F
import Data.Sequence
import Data.Monoid
import Data.Bits
}

-- %wrapper "posn"

$l = [a-zA-Z\192 - \255] # [\215 \247]    -- isolatin1 letter FIXME
$c = [A-Z\192-\221] # [\215]    -- capital isolatin1 letter FIXME
$s = [a-z\222-\255] # [\247]    -- small isolatin1 letter FIXME
$d = [0-9]                -- digit
$i = [$l $d _ ']          -- identifier character
$u = [\0-\255]          -- universal: any character

@rsyms =    -- symbols and non-identifier-like reserved words
   \. \* | \{ | \} | \; | \( | \) | \: | \= | \, | "else" \  "if" | \[ \] | \. | \? | \| \| | \& \& | \| | \^ | \& | \= \= | \! \= | \< | \> | \< \= | \> \= | \< \< | \> \> | \> \> \> | \+ | \- | \* | \/ | \% | \+ \+ | \- \- | \[ | \] | \. "this" | \. "class" | \~ | \! | \* \= | \/ \= | \% \= | \+ \= | \- \= | \< \< \= | \> \> \= | \> \> \> \= | \& \= | \^ \= | \| \=

:-
"//" [.]* ; -- Toss single line comments
"/*" ([$u # \*] | \* [$u # \/])* ("*")+ "/" ; 


$white+ ;
@rsyms { tok (\p s -> PT p (TS $ share s)) }
[1 2 3 4 5 6 7 8 9]$d * (u | U) { tok (\p s -> PT p (eitherResIdent (T_Unsigned . share) s)) }
[1 2 3 4 5 6 7 8 9]$d * (l | L) { tok (\p s -> PT p (eitherResIdent (T_Long . share) s)) }
[1 2 3 4 5 6 7 8 9]$d * (u l | U L) { tok (\p s -> PT p (eitherResIdent (T_UnsignedLong . share) s)) }
0 (x | X)($d | [a b c d e f]| [A B C D E F]) + { tok (\p s -> PT p (eitherResIdent (T_Hexadecimal . share) s)) }
0 (x | X)($d | [a b c d e f]| [A B C D E F]) + (u | U) { tok (\p s -> PT p (eitherResIdent (T_HexUnsigned . share) s)) }
0 (x | X)($d | [a b c d e f]| [A B C D E F]) + (l | L) { tok (\p s -> PT p (eitherResIdent (T_HexLong . share) s)) }
0 (x | X)($d | [a b c d e f]| [A B C D E F]) + (u l | U L) { tok (\p s -> PT p (eitherResIdent (T_HexUnsLong . share) s)) }
0 [0 1 2 3 4 5 6 7]* { tok (\p s -> PT p (eitherResIdent (T_Octal . share) s)) }
0 [0 1 2 3 4 5 6 7]* (u | U) { tok (\p s -> PT p (eitherResIdent (T_OctalUnsigned . share) s)) }
0 [0 1 2 3 4 5 6 7]* (l | L) { tok (\p s -> PT p (eitherResIdent (T_OctalLong . share) s)) }
0 [0 1 2 3 4 5 6 7]* (u l | U L) { tok (\p s -> PT p (eitherResIdent (T_OctalUnsLong . share) s)) }
($d + \. | \. $d +)((e | E)\- ? $d +)? | $d + (e | E)\- ? $d + | $d + \. $d + E \- ? $d + { tok (\p s -> PT p (eitherResIdent (T_JDouble . share) s)) }
($d + \. $d + | $d + \. | \. $d +)((e | E)\- ? $d +)? (f | F)| $d + (e | E)\- ? $d + (f | F) { tok (\p s -> PT p (eitherResIdent (T_JFloat . share) s)) }
($d + \. $d + | $d + \. | \. $d +)((e | E)\- ? $d +)? (l | L)| $d + (e | E)\- ? $d + (l | L) { tok (\p s -> PT p (eitherResIdent (T_JLongDouble . share) s)) }
\' \\ u ($d | [a b c d e f]| [A B C D E F]) ($d | [a b c d e f]| [A B C D E F]) ($d | [a b c d e f]| [A B C D E F]) ($d | [a b c d e f]| [A B C D E F]) \' { tok (\p s -> PT p (eitherResIdent (T_UnicodeChar . share) s)) }
\' ($u # [\' \\]| \\ [\' \\ n t r]) \' { tok (\p s -> PT p (eitherResIdent (T_JChar . share) s)) }

$l $i*   { tok (\p s -> PT p (eitherResIdent (TV . share) s)) }
\" ([$u # [\" \\ \n]] | (\\ (\" | \\ | \' | n | t)))* \"{ tok (\p s -> PT p (TL $ share $ unescapeInitTail s)) }

$d+      { tok (\p s -> PT p (TI $ share s))    }
$d+ \. $d+ (e (\-)? $d+)? { tok (\p s -> PT p (TD $ share s)) }

{

tok f p s = f p s

share :: String -> String
share = id

data Tok =
   TS !String     -- reserved words and symbols
 | TL !String     -- string literals
 | TI !String     -- integer literals
 | TV !String     -- identifiers
 | TD !String     -- double precision float literals
 | TC !String     -- character literals
 | T_Unsigned !String
 | T_Long !String
 | T_UnsignedLong !String
 | T_Hexadecimal !String
 | T_HexUnsigned !String
 | T_HexLong !String
 | T_HexUnsLong !String
 | T_Octal !String
 | T_OctalUnsigned !String
 | T_OctalLong !String
 | T_OctalUnsLong !String
 | T_JDouble !String
 | T_JFloat !String
 | T_JLongDouble !String
 | T_UnicodeChar !String
 | T_JChar !String

 deriving (Eq,Show,Ord)

data Token = 
   PT  Posn Tok
 | Err Posn
  deriving (Eq,Show,Ord)

tokenPos (PT (Pn _ l _) _ :_) = "line " ++ show l
tokenPos (Err (Pn _ l _) :_) = "line " ++ show l
tokenPos _ = "end of file"

posLineCol (Pn _ l c) = (l,c)
mkPosToken t@(PT p _) = (posLineCol p, prToken t)

prToken t = case t of
  PT _ (TS s) -> s
  PT _ (TI s) -> s
  PT _ (TV s) -> s
  PT _ (TD s) -> s
  PT _ (TC s) -> s
  PT _ (T_Unsigned s) -> s
  PT _ (T_Long s) -> s
  PT _ (T_UnsignedLong s) -> s
  PT _ (T_Hexadecimal s) -> s
  PT _ (T_HexUnsigned s) -> s
  PT _ (T_HexLong s) -> s
  PT _ (T_HexUnsLong s) -> s
  PT _ (T_Octal s) -> s
  PT _ (T_OctalUnsigned s) -> s
  PT _ (T_OctalLong s) -> s
  PT _ (T_OctalUnsLong s) -> s
  PT _ (T_JDouble s) -> s
  PT _ (T_JFloat s) -> s
  PT _ (T_JLongDouble s) -> s
  PT _ (T_UnicodeChar s) -> s
  PT _ (T_JChar s) -> s

  _ -> show t

data BTree = N | B String Tok BTree BTree deriving (Show)

eitherResIdent :: (String -> Tok) -> String -> Tok
eitherResIdent tv s = treeFind resWords
  where
  treeFind N = tv s
  treeFind (B a t left right) | s < a  = treeFind left
                              | s > a  = treeFind right
                              | s == a = t

resWords = b "int" (b "double" (b "catch" (b "break" (b "boolean" (b "abstract" N N) N) (b "case" (b "byte" N N) N)) (b "continue" (b "class" (b "char" N N) N) (b "do" (b "default" N N) N))) (b "float" (b "false" (b "extends" (b "else" N N) N) (b "finally" (b "final" N N) N)) (b "implements" (b "if" (b "for" N N) N) (b "instanceof" (b "import" N N) N)))) (b "static" (b "package" (b "native" (b "long" (b "interface" N N) N) (b "null" (b "new" N N) N)) (b "public" (b "protected" (b "private" N N) N) (b "short" (b "return" N N) N))) (b "throws" (b "synchronized" (b "switch" (b "super" N N) N) (b "throw" (b "this" N N) N)) (b "try" (b "true" (b "transient" N N) N) (b "while" (b "volatile" N N) N))))
   where b s = B s (TS s)

unescapeInitTail :: String -> String
unescapeInitTail = unesc . tail where
  unesc s = case s of
    '\\':c:cs | elem c ['\"', '\\', '\''] -> c : unesc cs
    '\\':'n':cs  -> '\n' : unesc cs
    '\\':'t':cs  -> '\t' : unesc cs
    '"':[]    -> []
    c:cs      -> c : unesc cs
    _         -> []

-------------------------------------------------------------------
-- Alex wrapper code.
-- A divide and conquer wrapper.
-------------------------------------------------------------------

type State = Int
type Transition = State -> Tokens -- Transition from in state to Tokens
data Tokens    = NoTokens
               | InvalidTokens String
               | Tokens {currentSeq :: Seq InternalToken
                        ,lastToken  :: Suffix
                        ,outState   :: State}
                 deriving Show
-- This is either a Sequence of tokens with another suffix, one token if the it
-- is in an accepting state or a string if it's not in an accepting state.
data Suffix = Str String 
            | One InternalToken
            | Multi Tokens 
                 deriving Show
-- Describes the size of the fingertree
data Size      = Size Int
                 deriving Show
type LexTree   = FingerTree (Table State Tokens,Size) Char
data InternalToken = Token { lexeme      :: String 
                           , token_id    :: Accepts}
type Accepts   = [AlexAcc (Posn -> String -> Token) ()]


tabulate :: (State,State) -> (State -> b) -> Table State b
access :: Table State b -> (State -> b)

instance Show b => Show (Table Int b) where
  show f = unlines $ [show i ++ " -> " ++ show (access f i) | i <- [0,7]]

-- Array tabulation
type Table a b = Array State b
tabulate range f = listArray range [f i | i <- [fst range..snd range]]
access a x = a ! x

instance Show InternalToken where
  show (Token lex accs) = case map (\acc -> case acc of 
    AlexAcc f -> show $ f (Pn 0 0 0) lex
    AlexAccSkip -> "Skip:" ++ show lex) accs of
                            [] -> "No Token:" ++ show lex ++ "\n"
                            toks -> unlines toks

instance Monoid Size where
  mempty = Size 0
  Size m `mappend` Size n = Size (m+n)

instance Monoid (Table State Tokens) where
  mempty = tabulate stateRange (\_ -> NoTokens)
  f `mappend` g = tabulate stateRange $ combineTokens (access f) (access g)

-- The base case for when one character is lexed.
instance F.Measured (Table State Tokens,Size) Char where
  measure c =
    let bytes = encode c
        baseCase in_state = case foldl automata in_state bytes of
          -1 -> InvalidTokens [c]
          os -> case alex_accept ! os of
            []  -> Tokens empty (Str [c]) os
            acc -> Tokens empty (One (Token [c] acc)) os
    in (tabulate stateRange $ baseCase, Size 1)

--------- Combination functions, the conquer step

-- Combines two transition maps
combineTokens :: Transition -> Transition -> Transition
combineTokens trans1 trans2 = \in_state -> case trans1 in_state of
  InvalidTokens s -> InvalidTokens s
  NoTokens -> trans2 in_state
  toks1 -> combineWithRHS toks1 trans2

-- Tries to merge tokens first, if it can't it either appends the token or calls
-- itself if the suffix contains Tokens instaed of a single token.
combineWithRHS :: Tokens -> Transition -> Tokens
combineWithRHS toks1 trans2 =
    let mid_state = outState toks1
        seq1 = currentSeq toks1
        startToks2 = trans2 startState
    in case trans2 mid_state of
      NoTokens -> toks1
      -- Not possible to merge tokens
      InvalidTokens _ -> case lastToken toks1 of
        Multi suffToks ->
          let toks2' = combineWithRHS suffToks trans2 -- try to merge suffix
          in appendTokens seq1 toks2'
        One tok -> appendTokens (seq1 |> tok) startToks2
        Str s -> InvalidTokens s -- Last token in toks1 is not accepting
      toks2 -> let toks2' = mergeTokens (lastToken toks1) toks2 trans2
               in appendTokens seq1 toks2'

suffToStr :: Suffix -> String
suffToStr (Str s) = s
suffToStr (One (Token s _)) = s
suffToStr (Multi (Tokens seq suff _)) = concatLexemes seq ++ suffToStr suff

-- Creates one token from the last token of the first sequence and and the first
-- token of the second sequence and inserts it between the init of the first
-- sequence and the tail of the second sequence
mergeTokens :: Suffix -> Tokens -> Transition -> Tokens
mergeTokens suff1 (Tokens seq2 suff2 out_state) trans2 = case viewl seq2 of
  token2 :< seq2' -> let newToken = mergeToken suff1 token2
                     in Tokens (newToken <| seq2') suff2 out_state
  EmptyL -> case alex_accept ! out_state of
    [] -> Tokens empty (mergeSuff suff1 suff2 trans2) out_state
    acc -> let newToken = (Token (suffToStr suff1 ++ suffToStr suff2) acc)
           in Tokens empty (One newToken) out_state

-- Creates on token from a suffix and a token
mergeToken :: Suffix -> InternalToken -> InternalToken
mergeToken suff1 (Token lex2 acc) = Token (suffToStr suff1 ++ lex2) acc

-- Creates the apropiet new suffix from two suffixes
mergeSuff :: Suffix -> Suffix -> Transition -> Suffix
mergeSuff (Multi toks1) _ trans2 = Multi $ combineWithRHS toks1 trans2
mergeSuff (Str s1) suff2 _ = Str $ s1 ++ suffToStr suff2
mergeSuff (One token1) (Str _) trans2 =
  let Tokens seq2 suff2 out_state = trans2 startState
  in Multi $ Tokens (token1 <| seq2) suff2 out_state
mergeSuff suff1 (One token2) _ = One $ mergeToken suff1 token2
mergeSuff suff1 (Multi toks2) trans2 = Multi $ mergeTokens suff1 toks2 trans2

-- Prepends a sequence of tokens on the sequence in Tokens
appendTokens :: Seq InternalToken -> Tokens -> Tokens
appendTokens seq1 (Tokens seq2 suff2 out_state) =
  Tokens (seq1 >< seq2) suff2 out_state
appendTokens _ _ = NoTokens

---------- Constructors

makeTree :: String -> LexTree
makeTree  = F.fromList

measureToTokens :: (Table State Tokens,Size) -> Seq Token
measureToTokens m = case access (fst $ m) startState of
  InvalidTokens s -> error $ "Unacceptable token: " ++ s
  NoTokens -> empty
  Tokens seq suff out_state -> foldlWithIndex showToken empty $ intToks seq suff
  where showToken toks i (Token lex accs) = case accs of
          [] -> toks
          AlexAcc f:_ -> toks |> f (Pn 0 0 i) lex
          AlexAccSkip:_ -> toks
        intToks seq (Str str) = error $ "Unacceptable token: " ++ str
        intToks seq (One token) = seq |> token
        intToks seq (Multi (Tokens seq' suff' _)) = intToks (seq >< seq') suff'

treeToTokens :: LexTree -> Seq Token
treeToTokens = measureToTokens . F.measure

------------- Util funs

concatLexemes :: Seq InternalToken -> String
concatLexemes = foldr ((++) . lexeme) ""

insertAtIndex :: String -> Int -> LexTree -> LexTree
insertAtIndex str i tree = 
  if i < 0
  then error "index must be >= 0"
  else l F.>< (makeTree str) F.>< r
     where (l,r) = splitTreeAt i tree

splitTreeAt :: Int -> LexTree -> (LexTree,LexTree)
splitTreeAt i tree = F.split (\(_,Size n) -> n>i) tree

-- Starting state
startState = 0
-- A tuple that says how many states there are
stateRange = bounds alex_accept

automata :: Int -> Byte -> Int
automata s c = let base   = alex_base ! s
                   ord_c  = fromEnum c
                   offset = base + ord_c
                   check  =  alex_check ! offset
               in if (offset >= (0)) && (check == ord_c)
                  then alex_table ! offset
                  else alex_deflt ! s

encode :: Char -> [Word8]
encode  = map fromIntegral . go . fromEnum
 where
  go oc
   | oc <= 0x7f       = [oc]
   | oc <= 0x7ff      = [ 0xc0 + (oc `shiftR` 6)
                        , 0x80 + oc .&. 0x3f
                        ]
   | oc <= 0xffff     = [ 0xe0 + (oc `shiftR` 12)
                        , 0x80 + ((oc `shiftR` 6) .&. 0x3f)
                        , 0x80 + oc .&. 0x3f
                        ]
   | otherwise        = [ 0xf0 + (oc `shiftR` 18)
                        , 0x80 + ((oc `shiftR` 12) .&. 0x3f)
                        , 0x80 + ((oc `shiftR` 6) .&. 0x3f)
                        , 0x80 + oc .&. 0x3f
                        ]
}
